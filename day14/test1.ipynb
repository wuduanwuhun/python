{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-09T10:22:37.464245Z",
     "start_time": "2025-01-09T10:22:37.457524Z"
    }
   },
   "source": [
    "# 完成DictVectorizer，CountVectorizer, TfidfVectorizer的练习，并理解其原理\n",
    "# 1.DictVectorizer 字典特征提取\n",
    "from  sklearn.feature_extraction import DictVectorizer\n",
    "def dictvectorizer():\n",
    "    dict = DictVectorizer(sparse=True) # 稀疏矩阵    \n",
    "    data = dict.fit_transform([{'city': '北京', 'temperature': 100},\n",
    "                                {'city': '上海', 'temperature': 60},\n",
    "                                {'city': '深圳', 'temperature': 30}])#字典\n",
    "    print(data)\n",
    "    print(\"特征的名字：\",dict.get_feature_names_out())#获取特征名称\n",
    "    print(dict.inverse_transform(data))#逆变换\n",
    "    return None\n",
    "dictvectorizer()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Compressed Sparse Row sparse matrix of dtype 'float64'\n",
      "\twith 6 stored elements and shape (3, 4)>\n",
      "  Coords\tValues\n",
      "  (0, 1)\t1.0\n",
      "  (0, 3)\t100.0\n",
      "  (1, 0)\t1.0\n",
      "  (1, 3)\t60.0\n",
      "  (2, 2)\t1.0\n",
      "  (2, 3)\t30.0\n",
      "特征的名字： ['city=上海' 'city=北京' 'city=深圳' 'temperature']\n",
      "[{'city=北京': np.float64(1.0), 'temperature': np.float64(100.0)}, {'city=上海': np.float64(1.0), 'temperature': np.float64(60.0)}, {'city=深圳': np.float64(1.0), 'temperature': np.float64(30.0)}]\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T11:25:30.247944Z",
     "start_time": "2025-01-09T11:25:30.236476Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 2.CountVectorizer:将文本中的词语转换为词频矩阵，例如矩阵中包含一个元素a[i][j]，它表示j词在i类文本下的词频。它通过 fit_transform 函数计算各个词语出现的次数，通过get_feature_names()可获取词袋中所有文本的关键字，通过 toarray()可看到词频矩阵的结果。\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "def countvectorizer():\n",
    "    vector = CountVectorizer(min_df=2)#最小词频2\n",
    "    res = vector.fit_transform(\n",
    "        [\"life is  short,i like python life\",\n",
    "         \"life is too long,i dislike python\",\n",
    "         \"life is short\"])#文本列表\n",
    "    print(vector.get_feature_names_out())#获取特征名称\n",
    "    print(res)#词频矩阵\n",
    "    print(type(res))#矩阵类型\n",
    "    print(res.toarray())#转为数组\n",
    "    print(vector.inverse_transform(res))#逆变换\n",
    "countvectorizer()"
   ],
   "id": "869be5af4cbe12a4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['is' 'life' 'python' 'short']\n",
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 10 stored elements and shape (3, 4)>\n",
      "  Coords\tValues\n",
      "  (0, 1)\t2\n",
      "  (0, 0)\t1\n",
      "  (0, 3)\t1\n",
      "  (0, 2)\t1\n",
      "  (1, 1)\t1\n",
      "  (1, 0)\t1\n",
      "  (1, 2)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 3)\t1\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "[[1 2 1 1]\n",
      " [1 1 1 0]\n",
      " [1 1 0 1]]\n",
      "[array(['life', 'is', 'short', 'python'], dtype='<U6'), array(['life', 'is', 'python'], dtype='<U6'), array(['life', 'is', 'short'], dtype='<U6')]\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T11:29:37.840181Z",
     "start_time": "2025-01-09T11:29:37.834040Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def countvec():\n",
    "    #对文本进行特征值化,单个汉字单个字母不统计，因为单个汉字字母没有意义\n",
    "    cv = CountVectorizer()\n",
    "    data = cv.fit_transform([\"人生苦短，我喜欢 python python\", \"人生漫长，不用 python\"])#文本列表\n",
    "    print(cv.get_feature_names_out())#获取特征名称\n",
    "    print(data)  #稀疏存储，只记录非零位置\n",
    "    print(data.toarray())#转为数组\n",
    "    return None\n",
    "countvec()"
   ],
   "id": "6f3e3ff44f90ebbe",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['python' '不用' '人生漫长' '人生苦短' '我喜欢']\n",
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 6 stored elements and shape (2, 5)>\n",
      "  Coords\tValues\n",
      "  (0, 3)\t1\n",
      "  (0, 4)\t1\n",
      "  (0, 0)\t2\n",
      "  (1, 0)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 1)\t1\n",
      "[[2 0 0 1 1]\n",
      " [1 1 1 0 0]]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T11:41:23.554902Z",
     "start_time": "2025-01-09T11:41:23.546370Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import jieba\n",
    "def cutword():\n",
    "    con1 = jieba.cut(\"今天很残酷，明天更残酷，后天很美好，但绝对大部分是死在明天晚上，所以每个人不要放弃今天。\")\n",
    "    con2 = jieba.cut(\"我们看到的从很远星系来的光是在几百万年之前发出的，这样当我们看到宇宙时，我们是在看它的过去。\")\n",
    "    con3 = jieba.cut(\n",
    "        \"如果只用一种方式了解某样事物，你就不会真正了解它。了解事物真正含义的秘密取决于如何将其与我们所了解的事物相联系。\")\n",
    "    # 转换成列表\n",
    "    print(type(con1))\n",
    "    # 把生成器转换成列表\n",
    "    content1 = list(con1)#分词结果\n",
    "    content2 = list(con2)\n",
    "    content3 = list(con3)\n",
    "    print(content1)\n",
    "    print(content2)\n",
    "    print(content3)\n",
    "    # 把列表转换成字符串,每个词之间用空格隔开\n",
    "    c1 = ' '.join(content1)#分词结果转为字符串，空格隔开\n",
    "    c2 = ' '.join(content2)\n",
    "    c3 = ' '.join(content3)\n",
    "    return c1, c2, c3\n",
    "\n",
    "def hanzivec():\n",
    "    c1, c2, c3 = cutword()  #jieba分词好的中文文本\n",
    "    print(c1)  #把分词好的文本打印出来\n",
    "    print(c2)\n",
    "    print(c3)\n",
    "\n",
    "    cv = CountVectorizer()#中文文本特征值化\n",
    "    data = cv.fit_transform([c1, c2, c3])#中文文本特征值化\n",
    "    print(cv.get_feature_names_out())  #把处理好后的特征名称打印出来\n",
    "    print(data.toarray())#转为数组\n",
    "    return None\n",
    "\n",
    "hanzivec()"
   ],
   "id": "741ed11bbebdcd88",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n",
      "['今天', '很', '残酷', '，', '明天', '更', '残酷', '，', '后天', '很', '美好', '，', '但', '绝对', '大部分', '是', '死', '在', '明天', '晚上', '，', '所以', '每个', '人', '不要', '放弃', '今天', '。']\n",
      "['我们', '看到', '的', '从', '很', '远', '星系', '来', '的', '光是在', '几百万年', '之前', '发出', '的', '，', '这样', '当', '我们', '看到', '宇宙', '时', '，', '我们', '是', '在', '看', '它', '的', '过去', '。']\n",
      "['如果', '只用', '一种', '方式', '了解', '某样', '事物', '，', '你', '就', '不会', '真正', '了解', '它', '。', '了解', '事物', '真正', '含义', '的', '秘密', '取决于', '如何', '将', '其', '与', '我们', '所', '了解', '的', '事物', '相', '联系', '。']\n",
      "今天 很 残酷 ， 明天 更 残酷 ， 后天 很 美好 ， 但 绝对 大部分 是 死 在 明天 晚上 ， 所以 每个 人 不要 放弃 今天 。\n",
      "我们 看到 的 从 很 远 星系 来 的 光是在 几百万年 之前 发出 的 ， 这样 当 我们 看到 宇宙 时 ， 我们 是 在 看 它 的 过去 。\n",
      "如果 只用 一种 方式 了解 某样 事物 ， 你 就 不会 真正 了解 它 。 了解 事物 真正 含义 的 秘密 取决于 如何 将 其 与 我们 所 了解 的 事物 相 联系 。\n",
      "['一种' '不会' '不要' '之前' '了解' '事物' '今天' '光是在' '几百万年' '发出' '取决于' '只用' '后天' '含义'\n",
      " '大部分' '如何' '如果' '宇宙' '我们' '所以' '放弃' '方式' '明天' '星系' '晚上' '某样' '残酷' '每个'\n",
      " '看到' '真正' '秘密' '绝对' '美好' '联系' '过去' '这样']\n",
      "[[0 0 1 0 0 0 2 0 0 0 0 0 1 0 1 0 0 0 0 1 1 0 2 0 1 0 2 1 0 0 0 1 1 0 0 0]\n",
      " [0 0 0 1 0 0 0 1 1 1 0 0 0 0 0 0 0 1 3 0 0 0 0 1 0 0 0 0 2 0 0 0 0 0 1 1]\n",
      " [1 1 0 0 4 3 0 0 0 0 1 1 0 1 0 1 1 0 1 0 0 1 0 0 0 1 0 0 0 2 1 0 0 1 0 0]]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-09T11:45:53.087486Z",
     "start_time": "2025-01-09T11:45:53.072904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#TfidfVectorize: tf 表示词频（某单词在某文本中的出现次数/该文本中所有词的词数），idf表示逆文本频率（语料库中包含某单词的文本数、的倒数、取log），tf-idf则表示词频 * 逆文档频率，tf-idf认为词的重要性随着它在文本中出现的次数成正比增加，但同时会随着它在整个语料库中出现的频率成反比下降。\n",
    "def tfidfvec():\n",
    "    c1, c2, c3 = cutword()\n",
    "    print(c1, c2, c3)\n",
    "    num = TfidfVectorizer(smooth_idf=True)#平滑idf\n",
    "    data = num.fit_transform([c1, c2, c3])#文本特征值化\n",
    "    print(num.get_feature_names_out())#特征名称\n",
    "    print((type(data)))#矩阵类型\n",
    "    print(data.toarray())#转为数组\n",
    "    return None\n",
    "tfidfvec()"
   ],
   "id": "140cd6611b2f1ebd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'generator'>\n",
      "['今天', '很', '残酷', '，', '明天', '更', '残酷', '，', '后天', '很', '美好', '，', '但', '绝对', '大部分', '是', '死', '在', '明天', '晚上', '，', '所以', '每个', '人', '不要', '放弃', '今天', '。']\n",
      "['我们', '看到', '的', '从', '很', '远', '星系', '来', '的', '光是在', '几百万年', '之前', '发出', '的', '，', '这样', '当', '我们', '看到', '宇宙', '时', '，', '我们', '是', '在', '看', '它', '的', '过去', '。']\n",
      "['如果', '只用', '一种', '方式', '了解', '某样', '事物', '，', '你', '就', '不会', '真正', '了解', '它', '。', '了解', '事物', '真正', '含义', '的', '秘密', '取决于', '如何', '将', '其', '与', '我们', '所', '了解', '的', '事物', '相', '联系', '。']\n",
      "今天 很 残酷 ， 明天 更 残酷 ， 后天 很 美好 ， 但 绝对 大部分 是 死 在 明天 晚上 ， 所以 每个 人 不要 放弃 今天 。 我们 看到 的 从 很 远 星系 来 的 光是在 几百万年 之前 发出 的 ， 这样 当 我们 看到 宇宙 时 ， 我们 是 在 看 它 的 过去 。 如果 只用 一种 方式 了解 某样 事物 ， 你 就 不会 真正 了解 它 。 了解 事物 真正 含义 的 秘密 取决于 如何 将 其 与 我们 所 了解 的 事物 相 联系 。\n",
      "['一种' '不会' '不要' '之前' '了解' '事物' '今天' '光是在' '几百万年' '发出' '取决于' '只用' '后天' '含义'\n",
      " '大部分' '如何' '如果' '宇宙' '我们' '所以' '放弃' '方式' '明天' '星系' '晚上' '某样' '残酷' '每个'\n",
      " '看到' '真正' '秘密' '绝对' '美好' '联系' '过去' '这样']\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "[[0.         0.         0.21821789 0.         0.         0.\n",
      "  0.43643578 0.         0.         0.         0.         0.\n",
      "  0.21821789 0.         0.21821789 0.         0.         0.\n",
      "  0.         0.21821789 0.21821789 0.         0.43643578 0.\n",
      "  0.21821789 0.         0.43643578 0.21821789 0.         0.\n",
      "  0.         0.21821789 0.21821789 0.         0.         0.        ]\n",
      " [0.         0.         0.         0.2410822  0.         0.\n",
      "  0.         0.2410822  0.2410822  0.2410822  0.         0.\n",
      "  0.         0.         0.         0.         0.         0.2410822\n",
      "  0.55004769 0.         0.         0.         0.         0.2410822\n",
      "  0.         0.         0.         0.         0.48216441 0.\n",
      "  0.         0.         0.         0.         0.2410822  0.2410822 ]\n",
      " [0.15698297 0.15698297 0.         0.         0.62793188 0.47094891\n",
      "  0.         0.         0.         0.         0.15698297 0.15698297\n",
      "  0.         0.15698297 0.         0.15698297 0.15698297 0.\n",
      "  0.1193896  0.         0.         0.15698297 0.         0.\n",
      "  0.         0.15698297 0.         0.         0.         0.31396594\n",
      "  0.15698297 0.         0.         0.15698297 0.         0.        ]]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "3cbfe6d3aa782e49"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
